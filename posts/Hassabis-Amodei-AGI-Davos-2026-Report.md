# The Day After AGI: Demis Hassabis & Dario Amodei at Davos 2026

## A Comprehensive Research Report

**Date:** January 2026
**Event:** World Economic Forum Annual Meeting, Davos
**Session:** "The Day After AGI"
**Moderator:** Zanny Minton Beddoes, Editor-in-Chief, The Economist

---

## Executive Summary

At Davos 2026, two of the most influential figures in artificial intelligence—**Demis Hassabis** (CEO, Google DeepMind, 2024 Nobel Prize laureate) and **Dario Amodei** (CEO, Anthropic)—shared a stage for their first public conversation in a year. Despite leading competing companies in the race to build AGI, both leaders converged on a striking consensus:

> "This is happening faster than most people realize, the disruption will be severe, and the window to get it right is shrinking."

---

## Table of Contents

1. [AGI Timeline Predictions](#1-agi-timeline-predictions)
2. [Impact on Jobs and Software Development](#2-impact-on-jobs-and-software-development)
3. [AI Safety and Existential Risks](#3-ai-safety-and-existential-risks)
4. [Geopolitical AI Competition](#4-geopolitical-ai-competition)
5. [The Post-AGI Vision](#5-the-post-agi-vision)
6. [Key Quotes](#6-key-quotes)
7. [Sources](#7-sources)

---

## 1. AGI Timeline Predictions

### The Core Disagreement

| Leader | AGI Timeline | Confidence |
|--------|-------------|------------|
| **Dario Amodei** | 2026-2027 | "Very hard to see how it could take longer" |
| **Demis Hassabis** | 5-10 years (2030-2035) | 50% chance by end of decade |

### Dario Amodei's Position

Amodei made aggressive predictions at Davos:

> "I don't think it will take long. It's hard for me to imagine it taking more time... I'm more confident than I've ever been that we're close to powerful capabilities in the next 2-3 years."

**Anthropic's official position** (March 2025 OSTP submission):
> "We expect powerful AI systems will emerge in late 2026 or early 2027" with "intellectual capabilities matching or exceeding that of Nobel Prize winners across most disciplines."

### Demis Hassabis's Position

Hassabis maintained a more cautious outlook:

> "Maybe we need one or two more breakthroughs before we'll get to AGI... Current systems are nowhere near human-level artificial general intelligence."

He identified missing capabilities in current systems:
- Ability to learn from few examples
- Continuous learning without catastrophic forgetting
- Better long-term memory
- Improved reasoning and planning
- Physical world understanding
- **World Models** - critical breakthrough needed

### How They Define AGI

**Amodei's Definition ("Powerful AI"):**
- Smarter than Nobel Prize winners across most fields
- Full human-equivalent interfaces (text, audio, video)
- End-to-end task completion
- "A country of geniuses in a datacenter"

**Hassabis's Definition (Scientific Discovery Capability):**
- **The Einstein Test:** Could an AI invent general relativity given 1900 information?
- Novel hypothesis generation, not just proving existing ones
- **Game Invention Test:** Could it invent a game as elegant as Go?
- No "jagged intelligence" (inconsistent performance)

### Evolution of Predictions Over Time

| Period | Amodei | Hassabis |
|--------|--------|----------|
| Oct 2024 | "Could come as early as 2026" | "As soon as 10 years" |
| Mar 2025 | "Late 2026 or early 2027" | "Five to ten years" |
| Jan 2026 | "Very hard to see longer" | "One or two breakthroughs needed" |

---

## 2. Impact on Jobs and Software Development

### Amodei's Striking Predictions

> "We might be 6-12 months away from models doing all of what software engineers do end-to-end."

> "I have engineers within Anthropic who say, I don't write any code anymore. I just let the model write the code. I edit it."

**Timeline predictions:**
- **Within 6-12 months:** AI performs most/all coding work
- **Within 2 years:** AI reaches "Nobel-level" scientific research
- **Within 5 years:** 50% of entry-level white-collar jobs disappear

### Hassabis on Job Displacement

> "We'll begin to see AI impacting internships as well as entry-level and junior-level jobs this year [2026]."

However, Hassabis maintained optimism about new opportunities:
> "Normal technological development over the next five years, in which some jobs disappear but new, possibly more valuable jobs are created."

His advice to students:
> "If I was to talk to a class of undergrads right now, I would be telling them to get really unbelievably proficient with these tools."

### Industry Validation

- **Microsoft CEO Satya Nadella:** AI now writes 20-30% of Microsoft's internal code
- **Salesforce CEO Marc Benioff:** Company stopped hiring new software engineers in 2025
- **Claude Opus 4.5:** Achieves 80.9% on SWE-bench Verified; scored higher than any human on Anthropic's engineering exam

### The "Zeroth World" Warning

Amodei warned about concentration of AI benefits:

> "The nightmare would be that there's this emerging 'zeroth world' country that's like 7 million people in Silicon Valley and 3 million people scattered throughout that is forming its own economy and becoming decoupled or disconnected."

### Industry Leader Responses

- **Jamie Dimon (JPMorgan CEO):** "We would agree if we have to [ban mass AI layoffs] to save society." Warned of potential "civil unrest."
- **Larry Fink (BlackRock CEO):** "What happens to everyone else if AI does to white-collar workers what globalization did to blue-collar workers?"
- **Kristalina Georgieva (IMF):** Described AI as a "tsunami" hitting the labor market, noting "40% of jobs are touched by AI."

---

## 3. AI Safety and Existential Risks

### Stance on "Doomism"

Both leaders explicitly rejected fatalism while acknowledging serious risks.

**Amodei:**
> "I think I've been skeptical of doomerism which is, you know, we're doomed, there is nothing we can do... This is a risk that if we all work together, we can address."

**Hassabis:**
> "I'm a big believer in human ingenuity. But the question is, having the time, and the focus, and all the best minds collaborating on it to solve these problems."

### Specific Risks Highlighted

| Risk Category | Details |
|---------------|---------|
| **Existential** | "The genie can't be put back in the bottle" (Hassabis) |
| **Infrastructure** | Cyberterror on energy/water systems "almost already happening" |
| **Economic** | Severe job displacement faster than society can adapt |
| **Autonomy** | Agentic AI systems becoming dangerous in wrong hands |
| **Geopolitical** | "1984 scenarios, or worse" if authoritarian states gain AGI |
| **Deception** | AI models demonstrating capabilities for duplicity |

### Safety Approaches

**Google DeepMind - Frontier Safety Framework:**
- Critical Capability Levels (CCLs)
- Deceptive Alignment Detection
- Automated Monitoring Systems
- Responsibility and Safety Council
- AGI Safety Council (led by co-founder Shane Legg)

**Anthropic - Responsible Scaling Policy:**
- AI Safety Levels (ASL-1 through ASL-3)
- Constitutional AI framework
- Mechanistic interpretability research
- ASL-3 activated for Claude Opus 4

### The Interpretability Race

Amodei sees interpretability as the key scientific breakthrough:

> "We are in a race between interpretability and model intelligence."

Recent progress has made researchers feel "on the verge of cracking interpretability in a big way" with a realistic path toward an "MRI for AI" within 5-10 years.

### Views on Regulation

**Amodei:**
> "I'm deeply uncomfortable with these decisions being made by a few companies, by a few people."

**Hassabis:**
> "Rules to control AI only work when most nations agree to them, and that's only getting harder... But it has to be international."

---

## 4. Geopolitical AI Competition

### Why They Cannot Slow Down

**Amodei's explanation:**
> "The reason we can't do that is because we have geopolitical adversaries building the same technologies at a similar pace. It's very hard to have an enforceable agreement where they slow down and we slow down."

> "I prefer Demis' timeline. I wish we had 5 to 10 years [before AGI]... But if we can just not sell the chips, then this isn't a question of competition between the U.S. and China."

### US-China AI Competition

**Amodei's Position (Urgent Concern):**

On Trump administration's decision to allow Nvidia chip sales to China:
> "I think this is crazy. It's a bit like selling nuclear weapons to North Korea and bragging that Boeing made the casings."

> "Not selling chips to China is one of the biggest things we can do to make sure we have time to handle this."

**Hassabis's Position (More Measured):**

> "[Chinese AI companies are] very good at catching up to where the frontier is... But I think they've yet to show they can innovate beyond the frontier."

Estimated Chinese labs are **6 months behind** (notably shorter than the 18-24 month gap previously cited).

> "To invent something is about 100 times harder than it is to copy it."

### The Chip Export Controversy

Trump administration's January 14, 2026 decision conditions:
- Third-party testing lab verification
- China cannot receive >50% of total chips sold to US customers
- Nvidia must certify sufficient US supply
- Chinese customers must implement security procedures
- 25% of revenue goes to US government

**Congressional response:** Republican lawmakers proposed the "AI Overwatch Act" for chip export oversight.

### Europe's Position

**Satya Nadella (Microsoft):**
> "Merely meeting internal European standards is not enough... true innovation must be able to stand in the global market."

**Jensen Huang (NVIDIA):**
> "Robotics is a once in lifetime opportunity for European countries."

However, Europe faces challenges including high energy costs and talent constraints.

---

## 5. The Post-AGI Vision

### "Uncharted Territory"

**Hassabis's core warning:**
> "After the arrival of AGI, we are in uncharted territory," pointing to questions about meaning and purpose that go beyond purely economic aspects.

> "Five to ten years isn't a lot of time."

### Questions of Meaning and Purpose

**Hassabis:**
> "Can we distribute the productivity gains fairly and widely around the world? And then there's still a question after that, of meaning and purpose. So that's the next philosophical question, which I actually think we need some great new philosophers to be thinking about today."

**Amodei:**
> Whether humanity survives its "technological adolescence" without self-destruction depends on how the next few years are used.

### Scientific Breakthroughs Expected

**The "Compressed 21st Century" (Amodei):**
> "AI-enabled biology and medicine will allow us to compress the progress that human biologists would have achieved over the next 50-100 years into 5-10 years."

**Healthcare predictions:**
- Reliable prevention/treatment of nearly all infectious diseases
- Elimination of most cancer
- Effective prevention and cures for genetic disease
- Prevention of Alzheimer's
- **Doubling of human lifespan to ~150 years**

**Hassabis's drug discovery vision:**
> AI could reduce drug development time "from years to weeks."

Goal: "Solve all disease" through systematic, AI-powered processes.

**Climate and Resources:**
> "If AGI technology is realized, global conflicts over scarce resources could gradually dissipate, ushering in a new era of peace and prosperity." (Hassabis)

### Preparing for the Transition

**For Individuals:**
> "Get really unbelievably proficient with these tools." (Hassabis)

**For Governments:**
> "I don't think there's an awareness at all of what is coming here and the magnitude of it... There's gonna need to be some role for government in the displacement that's this macroeconomically large." (Amodei)

**For Society:**
- New political philosophy needed
- Wealth redistribution mechanisms (UBI, universal basic services)
- International cooperation on safety standards
- Massive investment in interpretability research

### Personal Hopes and Fears

**Both leaders' surprising admission:**
> They would actually prefer if development proceeded somewhat more slowly, giving society more time to prepare.

**Hassabis's deeper motivation:**
> "This is my whole reason why I worked on AI and AGI my whole life, because I think it can be the ultimate tool to help us answer these kinds of questions [about the nature of reality]."

**Amodei's hope:**
> "It is critical to have a genuinely inspiring vision of the future, and not just a plan to fight fires... Fear is one kind of motivator, but it's not enough: we need hope as well."

---

## 6. Key Quotes

### On AGI Timelines

| Speaker | Quote |
|---------|-------|
| Amodei | "It's very hard for me to see how it could take longer than [2026-2027]" |
| Hassabis | "Current systems are nowhere near human-level AGI" |
| Hassabis | "Maybe we need one or two more breakthroughs" |

### On Jobs

| Speaker | Quote |
|---------|-------|
| Amodei | "I have engineers at Anthropic who say: I don't write any code anymore" |
| Amodei | "50% of entry-level white-collar jobs could disappear within five years" |
| Hassabis | "Get really unbelievably proficient with these tools" |

### On Safety

| Speaker | Quote |
|---------|-------|
| Hassabis | "The genie can't be put back in the bottle" |
| Amodei | "This is a risk that if we work together, we can address" |
| Both | Rejected extreme "doomism" while acknowledging serious risks |

### On Geopolitics

| Speaker | Quote |
|---------|-------|
| Amodei | "Selling chips to China is like selling nuclear weapons to North Korea" |
| Hassabis | "Chinese labs are about six months behind" |
| Amodei | "Not selling chips is one of the biggest things we can do" |

### On the Future

| Speaker | Quote |
|---------|-------|
| Hassabis | "After the arrival of AGI, we are in uncharted territory" |
| Amodei | "We're knocking on the door of incredible capabilities" |
| Both | "We would prefer if development proceeded somewhat more slowly" |

---

## 7. Sources

### Primary Sources - Davos 2026

- [World Economic Forum: The Day After AGI Session](https://www.weforum.org/meetings/world-economic-forum-annual-meeting-2026/sessions/the-day-after-agi/)
- [Fortune: AI luminaries at Davos clash over how close human level intelligence really is](https://fortune.com/2026/01/23/deepmind-demis-hassabis-anthropic-dario-amodei-yann-lecun-ai-davos/)
- [Euronews: AI at Davos 2026](https://www.euronews.com/next/2026/01/20/ai-at-davos-2026-from-work-to-useful-and-safe-ai-heres-what-the-tech-leaders-have-said)

### Analysis and Commentary

- [The Day After AGI: What Demis Hassabis and Dario Amodei said at WEF - abZ Global](https://www.abzglobal.net/web-development-blog/the-day-after-agi-what-demis-hassabis-and-dario-amodei-said-at-the-world-economic-forum)
- [What Amodei and Hassabis said about AGI timelines, jobs, and China - Medium](https://jpcaparas.medium.com/what-amodei-and-hassabis-said-about-agi-timelines-jobs-and-china-at-davos-156308aa12c3)
- [Hassabis and Amodei interview at Davos 2026 - Medium](https://medium.com/@ZombieCodeKill/hassabis-and-amodei-interview-at-davos-2026-ad719642d289)
- [Digital Watch: Davos 2026 reveals competing visions for AI](https://dig.watch/updates/davos-2026-reveals-competing-visions-for-ai)

### Geopolitical Coverage

- [Bloomberg: Anthropic CEO Says AI Chip Sales to China Like Selling Nukes to North Korea](https://www.bloomberg.com/news/articles/2026-01-20/anthropic-ceo-says-selling-advanced-ai-chips-to-china-is-crazy)
- [Bloomberg: DeepMind CEO Says Chinese AI Firms Are 6 Months Behind the West](https://www.bloomberg.com/news/articles/2026-01-20/deepmind-ceo-says-chinese-ai-firms-are-6-months-behind-the-west)
- [SiliconANGLE: Anthropic boss slams Trump over AI chip sales to China](https://siliconangle.com/2026/01/20/anthropic-boss-dario-amodei-slams-trump-crazy-decision-sell-advanced-ai-chips-china/)

### Jobs and Economic Impact

- [Yahoo Finance: Anthropic CEO Predicts AI Models Will Replace Software Engineers](https://finance.yahoo.com/news/anthropic-ceo-predicts-ai-models-233113047.html)
- [Yahoo Finance: At Davos, fears about AI-driven job loss take center stage](https://finance.yahoo.com/news/at-davos-fears-about-ai-driven-job-loss-take-center-stage-124805401.html)
- [Fortune: JPMorgan CEO welcomes government ban on mass AI layoffs](https://fortune.com/2026/01/22/jpmorgan-chase-ceo-jamie-dimon-ai-layoff-income-assist-workers-elon-musk-sam-altman-universal-basic-income/)
- [Fortune: BlackRock CEO Larry Fink warns AI could be capitalist failure](https://fortune.com/2026/01/20/blackrock-billionaire-ceo-larry-fink-capitalism-critique-ai-world-economic-forum-davos/)

### Safety and Technical

- [Anthropic: Responsible Scaling Policy](https://www.anthropic.com/news/anthropics-responsible-scaling-policy)
- [Anthropic: Activating ASL-3 Protections](https://www.anthropic.com/news/activating-asl3-protections)
- [Google DeepMind: Frontier Safety Framework](https://deepmind.google/blog/introducing-the-frontier-safety-framework/)
- [Dario Amodei: The Urgency of Interpretability](https://www.darioamodei.com/post/the-urgency-of-interpretability)
- [CBS News: Why Anthropic CEO warns of AI's potential dangers](https://www.cbsnews.com/news/anthropic-ceo-dario-amodei-warning-of-ai-potential-dangers-60-minutes-transcript/)

### Background and Context

- [TIME: Demis Hassabis TIME100 Interview](https://time.com/7277608/demis-hassabis-interview-time100-2025/)
- [CNBC: AI that can match humans at any task in 5-10 years](https://www.cnbc.com/2025/03/17/human-level-ai-will-be-here-in-5-to-10-years-deepmind-ceo-says.html)
- [Dario Amodei: Machines of Loving Grace (Essay)](https://www.darioamodei.com/essay/machines-of-loving-grace)
- [Axios: Transformative AGI is on the horizon](https://www.axios.com/2025/12/05/ai-deepmind-gemini-agi)
- [Council on Foreign Relations: How 2026 Could Decide the Future of AI](https://www.cfr.org/articles/how-2026-could-decide-future-artificial-intelligence)
- [Lex Fridman Podcast #475: Demis Hassabis Transcript](https://lexfridman.com/demis-hassabis-2-transcript/)

---

*Report compiled from deep research conducted by 5 specialized research agents analyzing multiple primary and secondary sources from the World Economic Forum 2026 and related coverage.*

*Last updated: January 24, 2026*
